% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fold.R
\name{fold}
\alias{fold}
\alias{create_balanced_groups}
\title{Create balanced folds for cross-validation.}
\usage{
fold(data, k = 5, cat_col = NULL, num_col = NULL, id_col = NULL,
  starts_col = NULL, method = "n_dist", id_aggregation_fn = sum,
  extreme_pairing_levels = 1, remove_missing_starts = FALSE,
  num_fold_cols = 1, unique_fold_cols_only = TRUE, max_iters = 5,
  handle_existing_fold_cols = "keep_warn", parallel = FALSE)
}
\arguments{
\item{data}{Dataframe or Vector.}

\item{k}{\emph{Dependent on method.}

 Number of folds (default), fold size, with more (see \code{method}).

 Given as whole number and/or percentage (0 < n < 1).}

\item{cat_col}{Name of categorical variable to balance between folds.

 E.g. when predicting a binary variable (a or b), it is necessary to have
 both represented in every fold.

 N.B. If also passing an \code{id_col}, \code{cat_col} should be constant within each ID.}

\item{num_col}{Name of numerical variable to balance between folds.

 N.B. When used with \code{id_col}, values for each ID are aggregated using \code{id_aggregation_fn} before being balanced.

 N.B. When passing \code{num_col}, the \code{method} parameter is not used.}

\item{id_col}{Name of factor with IDs.
 This will be used to keep all rows that share an ID in the same fold
 (if possible).

 E.g. If we have measured a participant multiple times and want to see the
 effect of time, we want to have all observations of this participant in
 the same fold.}

\item{starts_col}{Name of column with values to match in method \code{l_starts}
when data is a dataframe. Pass \code{'index'} to use row names. (Character)}

\item{method}{\code{greedy}, \code{n_dist}, \code{n_fill}, \code{n_last},
 \code{n_rand}, \code{l_sizes}, \code{l_starts}, \code{staircase}, or
 \code{primes}.

 \strong{Notice}: examples are sizes of the generated groups
 based on a vector with 57 elements.

 \subsection{greedy}{Divides up the data greedily given a specified group size
 \eqn{(e.g. 10, 10, 10, 10, 10, 7)}.

 \code{n} is group size}

 \subsection{n_dist (default)}{Divides the data into a specified number of groups and
 distributes excess data points across groups
 \eqn{(e.g. 11, 11, 12, 11, 12)}.

 \code{n} is number of groups}

 \subsection{n_fill}{Divides the data into a specified number of groups and
 fills up groups with excess data points from the beginning
 \eqn{(e.g. 12, 12, 11, 11, 11)}.

 \code{n} is number of groups}

 \subsection{n_last}{Divides the data into a specified number of groups.
 It finds the most equal group sizes possible,
 using all data points. Only the last group is able to differ in size
 \eqn{(e.g. 11, 11, 11, 11, 13)}.

 \code{n} is number of groups}

 \subsection{n_rand}{Divides the data into a specified number of groups.
 Excess data points are placed randomly in groups (only 1 per group)
 \eqn{(e.g. 12, 11, 11, 11, 12)}.

 \code{n} is number of groups}

 \subsection{l_sizes}{Divides up the data by a list of group sizes.
 Excess data points are placed in an extra group at the end.
 \eqn{(e.g. n = list(0.2,0.3) outputs groups with sizes (11,17,29))}.

 \code{n} is a list of group sizes}

 \subsection{l_starts}{Starts new groups at specified values of vector.

 \code{n} is a list of starting positions.
 Skip values by c(value, skip_to_number) where skip_to_number is the nth appearance of the value
 in the vector.
 Groups automatically start from first data point.

 \eqn{E.g. n = c(1,3,7,25,50) outputs groups with sizes (2,4,18,25,8)}.

 To skip: \eqn{given vector c("a", "e", "o", "a", "e", "o"), n = list("a", "e", c("o", 2))
 outputs groups with sizes (1,4,1)}.}

 If passing \eqn{n = 'auto'}  the starting positions are automatically found with
 \code{\link{find_starts}()}.

 \subsection{staircase}{Uses step size to divide up the data.
 Group size increases with 1 step for every group,
 until there is no more data
 \eqn{(e.g. 5, 10, 15, 20, 7)}.

 \code{n} is step size}

 \subsection{primes}{Uses prime numbers as group sizes.
 Group size increases to the next prime number
 until there is no more data.
 \eqn{(e.g. 5, 7, 11, 13, 17, 4)}.

 \code{n} is the prime number to start at}}

\item{id_aggregation_fn}{Function for aggregating values in \code{num_col} for each ID, before balancing \code{num_col}.

 N.B. Only used when \code{num_col} and \code{id_col} are both specified.}

\item{extreme_pairing_levels}{How many levels of extreme pairing to do
 when \code{num_col} is not \code{NULL}.

 \strong{Extreme pairing}: Rows/pairs are ordered as smallest, largest,
 second smallest, second largest, etc. If \code{extreme_pairing_levels > 1},
 this is done "recursively". See \code{"Details/num_col"} for more.

 N.B. Works best with large datasets. If set too high,
 the result might not be stochastic. Always check if an increase
 actually makes the folds more balanced. See example.}

\item{remove_missing_starts}{Recursively remove elements from the
list of starts that are not found.
For method \code{l_starts} only.
(Logical)}

\item{num_fold_cols}{Number of fold columns to create.
 Useful for repeated cross-validation.

 If \code{num_fold_cols > 1}, columns will be named \eqn{".folds_1"}, \eqn{".folds_2"}, etc.
 Otherwise simply \eqn{".folds"}.

 N.B. If \code{unique_fold_cols_only} is \code{TRUE},
 we can end up with fewer columns than specified, see \code{max_iters}.

 N.B. If \code{data} has existing fold columns, see \code{handle_existing_fold_cols}.}

\item{unique_fold_cols_only}{Check if fold columns are identical and keep only unique columns.

 As the number of column comparisons can be time consuming,
 we can run this part in parallel. See \code{parallel}.

 N.B. We can end up with fewer columns than specified in \code{num_fold_cols}, see \code{max_iters}.

 N.B. Only used when \code{num_fold_cols > 1} or \code{data} has existing fold columns.}

\item{max_iters}{Maximum number of attempts at reaching \code{num_fold_cols} \emph{unique} fold columns.

 When only keeping unique fold columns, we risk having fewer columns than expected.
 Hence, we repeatedly create the missing columns and remove those that are not unique. This is done until
 we have \code{num_fold_cols} unique fold columns or we have attempted \code{max_iters} times.
 In some cases, it is not possible to create \code{num_fold_cols} unique combinations of our dataset, e.g.
 when specifying \code{cat_col}, \code{id_col} and \code{num_col}.
 \code{max_iters} specifies when to stop trying.
 Note that we can end up with fewer columns than specified in \code{num_fold_cols}.

 N.B. Only used \code{num_fold_cols > 1}.}

\item{handle_existing_fold_cols}{How to handle existing fold columns.
 Either "keep_warn", "keep", or "remove".

 To add extra fold columns, use "keep" or "keep_warn". Note that existing fold columns might be renamed.

 To replace the existing fold columns, use "remove".}

\item{parallel}{Whether to parallelize the fold column comparisons,
 when \code{unique_fold_cols_only} is \code{TRUE}.

 Requires a registered parallel backend.
 See \code{\link[doParallel:registerDoParallel]{doParallel::registerDoParallel}}.}
}
\value{
Dataframe with grouping factor for subsetting in cross-validation.
}
\description{
Divides data into groups by a range of methods.
 Balances a given categorical variable and/or numerical variable between folds and keeps (if possible)
 all data points with a shared ID (e.g. participant_id) in the same fold.
 Can create multiple unique fold columns for repeated cross-validation.
}
\details{
\subsection{cat_col}{
   \enumerate{
     \item Data is subset by \code{cat_col}.
     \item Subsets are grouped and merged.
   }
 }

 \subsection{id_col}{
   \enumerate{
     \item Groups are created from unique IDs.
   }
 }

 \subsection{num_col}{
   \enumerate{
     \item Rows are shuffled.

     \strong{Note} that this will only affect rows with the same value in \code{num_col}.
     \item Extreme pairing 1: Rows are ordered as smallest, largest, second smallest, second largest, etc.
     Each pair get a group identifier.
     \item If \code{extreme_pairing_levels > 1}: The group identifiers are reordered as smallest,
     largest, second smallest, second largest, etc., by the sum of \code{num_col} in the represented rows.
     These pairs (of pairs) get a new set of group identifiers, and the process is repeated
      \code{extreme_pairing_levels-2} times. Note that the group identifiers at the last level will represent
      \code{2^extreme_pairing_levels} rows, why you should be careful when choosing that setting.
     \item The final group identifiers are folded, and the fold identifiers are transferred to the rows.
   }

 N.B. When doing extreme pairing of an unequal number of rows/groups,
 the row/group with the smallest value is placed in a group by itself, and the order is instead:
 smallest, second smallest, largest, third smallest, second largest, etc.
 }

 \subsection{cat_col AND id_col}{
   \enumerate{
     \item Data is subset by \code{cat_col}.
     \item Groups are created from unique IDs in each subset.
     \item Subsets are merged.
   }
 }

 \subsection{cat_col AND num_col}{
   \enumerate{
     \item Data is subset by \code{cat_col}.
     \item Subsets are grouped by \code{num_col}.
     \item Subsets are merged.
   }
 }

 \subsection{num_col AND id_col}{
   \enumerate{
     \item Values in \code{num_col} are aggregated for each ID, using \code{id_aggregation_fn}.
     \item The IDs are grouped, using the aggregated values as "\code{num_col}".
     \item The group numbers for IDs are transferred to their rows.
   }
 }

 \subsection{cat_col AND num_col AND id_col}{
   \enumerate{
     \item Values in \code{num_col} are aggregated for each ID, using \code{id_aggregation_fn}.
     \item IDs are subset by \code{cat_col}.
     \item The IDs for each subset are grouped,
     by using the aggregated values as "\code{num_col}".
     \item The group numbers for IDs are transferred to their rows.
   }
 }
}
\examples{
# Attach packages
library(groupdata2)
library(dplyr)

# Create dataframe
df <- data.frame(
 "participant" = factor(rep(c('1','2', '3', '4', '5', '6'), 3)),
 "age" = rep(sample(c(1:100), 6), 3),
 "diagnosis" = rep(c('a', 'b', 'a', 'a', 'b', 'b'), 3),
 "score" = sample(c(1:100), 3*6))
df <- df \%>\% arrange(participant)
df$session <- rep(c('1','2', '3'), 6)

# Using fold()

## Without balancing
df_folded <- fold(df, 3, method = 'n_dist')

## With cat_col
df_folded <- fold(df, 3, cat_col = 'diagnosis',
 method = 'n_dist')

## With id_col
df_folded <- fold(df, 3, id_col = 'participant',
 method = 'n_dist')

## With num_col
# Note: 'method' would not be used in this case
df_folded <- fold(df, 3, num_col = 'score')

# With cat_col and id_col
df_folded <- fold(df, 3, cat_col = 'diagnosis',
 id_col = 'participant', method = 'n_dist')

## With cat_col, id_col and num_col
df_folded <- fold(df, 3, cat_col = 'diagnosis',
 id_col = 'participant', num_col = 'score')

# Order by folds
df_folded <- df_folded \%>\% arrange(.folds)

## Multiple fold columns
# Useful for repeated cross-validation
df_folded <- fold(df, 3, cat_col = 'diagnosis',
 id_col = 'participant', num_fold_cols = 5,
 unique_fold_cols_only=TRUE,
 max_iters=4)

## Check if additional extreme_pairing_levels
## improve the numerical balance
set.seed(2) # try with seed 1 as well
df_folded_1 <- fold(df, 3, num_col = 'score',
                     extreme_pairing_levels = 1)
df_folded_1 \%>\%
  dplyr::group_by(.folds) \%>\%
  dplyr::summarise(sum_score = sum(score),
                   mean_score = mean(score))

set.seed(2) # try with seed 1 as well
df_folded_2 <- fold(df, 3, num_col = 'score',
                     extreme_pairing_levels = 2)
df_folded_2 \%>\%
  dplyr::group_by(.folds) \%>\%
  dplyr::summarise(sum_score = sum(score),
                   mean_score = mean(score))

}
\author{
Ludvig Renbo Olsen, \email{r-pkgs@ludvigolsen.dk}
}
